{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = '../../datasets/rawdata/'\n",
    "dataset = '../../datasets/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ramad\\Documents\\cnn\\cnn-mr-team\\src\\models\\preprocessing.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mface_detect\u001b[39m(img, path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Convert into grayscale\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Load the cascade\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\ramad\\Documents\\cnn\\cnn-mr-team\\src\\models\\preprocessing.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mface_detect\u001b[39m(img, path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Convert into grayscale\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ramad/Documents/cnn/cnn-mr-team/src/models/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Load the cascade\u001b[39;00m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ramad\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ramad\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def face_detect(img, path):\n",
    "    # Convert into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "      x, y, w, h = faces[0]  # Menggunakan wajah pertama yang terdeteksi\n",
    "      cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "      face = img[y:y+h, x:x+w]  # Memotong bagian wajah\n",
    "\n",
    "      if face.size > 0:\n",
    "        face = cv2.resize(face, (128, 128))\n",
    "        cv2.imwrite(path, face)\n",
    "        return True\n",
    "      else:\n",
    "        print(\"Area Wajah Tidak Terdeteksi \" + path)\n",
    "        return False\n",
    "    else:\n",
    "      print(\"Wajah Tidak Terdeteksi \" + path)\n",
    "      return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wajah Tidak Terdeteksi ../../datasets/dataset/2017051017\\IMG-20230302-WA0016.png\n",
      "Wajah Tidak Terdeteksi ../../datasets/dataset/2117051048\\WIN_20231003_13_35_27_Pro.jpg\n",
      "Wajah Tidak Terdeteksi ../../datasets/dataset/2117051048\\WIN_20231003_13_35_29_Pro.jpg\n",
      "Wajah Tidak Terdeteksi ../../datasets/dataset/2117051048\\WIN_20231003_13_35_31_Pro.jpg\n",
      "Wajah Tidak Terdeteksi ../../datasets/dataset/2117051048\\WIN_20231003_13_43_48_Pro.jpg\n",
      "Wajah Tidak Terdeteksi ../../datasets/dataset/2157051001\\WIN_20231002_21_48_23_Pro.jpg\n",
      "Jumlah foto yang tidak terdeteksi: 6\n"
     ]
    }
   ],
   "source": [
    "fail_detect = 0\n",
    "\n",
    "for npm_folder in os.listdir(rawdata):\n",
    "    npm_path = os.path.join(rawdata, npm_folder)\n",
    "\n",
    "    if os.path.isdir(npm_path):\n",
    "        # Membuat folder NPM di dalam folder \"dataset\"\n",
    "        npm_dataset_folder = os.path.join(dataset, npm_folder)\n",
    "        os.makedirs(npm_dataset_folder, exist_ok=True)\n",
    "\n",
    "        # Loop melalui semua file gambar di folder NPM\n",
    "        for img_file in os.listdir(npm_path):\n",
    "            img_path = os.path.join(npm_path, img_file)\n",
    "\n",
    "            if os.path.isfile(img_path):\n",
    "                # Deteksi wajah dan simpan ke folder NPM di \"dataset\"\n",
    "                output_path = os.path.join(npm_dataset_folder, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                result = face_detect(img, output_path)\n",
    "                if not result:\n",
    "                    fail_detect += 1\n",
    "            else:\n",
    "                print(\"Failed to load image: \" + img_path)\n",
    "                fail_detect += 1\n",
    "\n",
    "print('Jumlah foto yang tidak terdeteksi:', fail_detect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
